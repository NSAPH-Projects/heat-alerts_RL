_target_: sb3_contrib.RecurrentPPO
policy: MlpLstmPolicy
n_steps: 512 # 2048 # 128
gamma: 1.0
learning_rate: 0.0003
policy_kwargs:
  net_arch: [16, 16]
  lstm_hidden_size: 128