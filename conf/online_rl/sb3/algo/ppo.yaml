_target_: stable_baselines3.PPO
policy: MlpPolicy
n_steps: 2048 # 512 # 256
learning_rate: 0.001
policy_kwargs:
  net_arch: [16, 16]
