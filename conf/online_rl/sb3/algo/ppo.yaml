_target_: stable_baselines3.PPO
policy: MlpPolicy
n_steps: 256 # 2048
learning_rate: 0.001
policy_kwargs:
  net_arch: [16, 16]
